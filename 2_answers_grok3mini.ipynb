{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51ed89d8-5e29-46b6-8bf6-51bac1f2e82e",
   "metadata": {},
   "source": [
    "# Data Collection for System Under Test\n",
    "This notebook implements the collection of $N$ independent generations from a target model (grok-3-mini via Azure) at a nominal temperature $T=0$ on the chosen prompt dataset (must be the same used for the reference models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7d3686-4b59-4179-8e9a-ace2d04de3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import tiktoken\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14662767-c6cd-47f9-acd4-5232329aeac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"\"                         # insert ENDPOINT\n",
    "model_name = \"grok-3-mini\"\n",
    "deployment = \"\"                       # insert DEPLOYMENT NAME\n",
    "\n",
    "subscription_key = \"\"                 # insert SUBSCRIPTION KEY\n",
    "api_version = \"\"                      # insert API VERSION\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    ")\n",
    "\n",
    "# The choice of tokenizer is independent of the model under test, as the objective is to compute variability metrics across distributions of tokenized sequences.\n",
    "# Here, we use the 'o200k_base' encoding (standard for GPT-4o family).\n",
    "tokenizer = tiktoken.get_encoding('o200k_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98732ab-c782-425f-8f04-6edab7e7150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = load_dataset(\"truthfulqa/truthful_qa\", 'generation')['validation']['question'][:30]   #must be the same as the one used for the reference models\n",
    "N = 100                                                                                         #can be different respect to the one used for the reference models\n",
    "tok_limit = 32                                                                                  #must be the same as the one used for the reference models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8693e5-378b-4602-a927-3d57030eb045",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_grok = {}\n",
    "\n",
    "for q in tqdm(prompts):\n",
    "    messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": q,\n",
    "            }\n",
    "        ]\n",
    "    answs = []\n",
    "    for i in range(N):\n",
    "        response = client.chat.completions.create(\n",
    "                messages=messages,\n",
    "                max_completion_tokens=tok_limit,\n",
    "                model=deployment,\n",
    "                temperature = 0.0\n",
    "            )\n",
    "        answs.append(tokenizer.encode(response.choices[0].message.content))\n",
    "    answers_grok[q] = answs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96d9f19-585c-457d-a4d2-d013948e71b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"answers_grok.json\", \"w\") as f:\n",
    "    json.dump(answers_grok, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9904d8e-ae25-4fc8-a2d5-404fecc6b2d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
